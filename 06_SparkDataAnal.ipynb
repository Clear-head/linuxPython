{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2878373-9b60-49aa-8749-cf255348c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f38142f-0e70-4dd7-832f-c57c9ef10895",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "039381ba-0dec-49a8-a97f-72bbface7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = spark.read.format('json').load('../learning_spark_data/2015-summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b062723d-8a25-4eae-9053-dd52faa4fe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4187bdd-005e-489c-8bf6-aadb0248fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|   15|\n",
      "|    1|\n",
      "|  344|\n",
      "|   15|\n",
      "|   62|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e211e39f-6ef4-4194-835a-1a5cb70876f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('DEST_COUNTRY_NAME').drop_duplicates().show() == df.select('DEST_COUNTRY_NAME').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe3dbd74-3eb6-4e08-af2a-2e481b2cec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row('hello', None, 1)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make one record from Row class\n",
    "from pyspark.sql import Row\n",
    "\n",
    "mr = Row('hello', None, 1)\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c15a7c6-3425-426c-9a0a-87aa3c829ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df3 = df.withColumn('withinCountry', expr('ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c530e8f-b146-4818-85a6-22faaddcc3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbfa977a-9b09-44f6-9651-ea6c92145586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|withinCountry|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "|    United States|      United States|370002|         true|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.filter(df3.withinCountry==True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2313a6be-5e1d-442e-8408-51f7bfd3070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+-------------+--------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|category|\n",
      "+--------------------+-------------------+-----+-------------+--------+\n",
      "|       United States|            Romania|   15|        false|   upper|\n",
      "|       United States|            Croatia|    1|        false|   under|\n",
      "|       United States|            Ireland|  344|        false|   upper|\n",
      "|               Egypt|      United States|   15|        false|   upper|\n",
      "|       United States|              India|   62|        false|   upper|\n",
      "|       United States|          Singapore|    1|        false|   under|\n",
      "|       United States|            Grenada|   62|        false|   upper|\n",
      "|          Costa Rica|      United States|  588|        false|   upper|\n",
      "|             Senegal|      United States|   40|        false|   upper|\n",
      "|             Moldova|      United States|    1|        false|   under|\n",
      "|       United States|       Sint Maarten|  325|        false|   upper|\n",
      "|       United States|   Marshall Islands|   39|        false|   upper|\n",
      "|              Guyana|      United States|   64|        false|   upper|\n",
      "|               Malta|      United States|    1|        false|   under|\n",
      "|            Anguilla|      United States|   41|        false|   upper|\n",
      "|             Bolivia|      United States|   30|        false|   upper|\n",
      "|       United States|           Paraguay|    6|        false|   under|\n",
      "|             Algeria|      United States|    4|        false|   under|\n",
      "|Turks and Caicos ...|      United States|  230|        false|   upper|\n",
      "|       United States|          Gibraltar|    1|        false|   under|\n",
      "+--------------------+-------------------+-----+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case when 카운트 10 이하 under, 이상 upper로 변환 > category 컬럼 추가\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df3.withColumn(\n",
    "    \"category\",\n",
    "    when(df3[\"count\"] <= 10, \"under\").otherwise(\"upper\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "918eb2c7-d52a-4c1e-ada4-58df08feaf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|category|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "|    United States|            Romania|   15|        false|   upper|\n",
      "|    United States|            Croatia|    1|        false|   under|\n",
      "|    United States|            Ireland|  344|        false|   upper|\n",
      "+-----------------+-------------------+-----+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.createOrReplaceTempView(\"df3_view\")\n",
    "query = '''\n",
    "SELECT *,\n",
    "       CASE \n",
    "           WHEN count <= 10 THEN 'under'\n",
    "           ELSE 'upper'\n",
    "       END AS category\n",
    "FROM df3_view\n",
    "'''\n",
    "spark.sql(query).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0b7f48b-1e20-48bb-8952-a7cc2dff0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7103e40-91b0-4fcb-8285-f8584dc27429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_df, dept_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7658ef7b-871d-4bf3-8e75-d976e61bed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c916bfea-a744-4cb1-8bbc-aa1dcedac60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: date (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- deptno: integer (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df  = spark.read.format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('inferSchema', 'true')\\\n",
    "            .load('../learning_spark_data/emp.csv')\n",
    "emp_df.printSchema()\n",
    "dept_df  = spark.read.format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('inferSchema', 'true')\\\n",
    "            .load('../learning_spark_data/dept.csv')\n",
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "482a5fdc-e4f1-485d-8170-432773d882e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "83e4f9cc-4c25-471e-bca5-c5397ca4f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+\n",
      "|deptno|     dname|     loc|\n",
      "+------+----------+--------+\n",
      "|    10|ACCOUNTING|NEW YORK|\n",
      "|    20|  RESEARCH|  DALLAS|\n",
      "|    30|     SALES| CHICAGO|\n",
      "|    40|OPERATIONS|  BOSTON|\n",
      "+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8311125-9844-4262-be4a-a83ac1a61497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select('*').where('deptno==10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f559fca9-2ffe-4579-97ae-260c684b3159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, first, last, min, max, sum, avg, count, round\n",
    "\n",
    "emp_df.select(countDistinct('job')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1e6d5d04-c801-4d53-bcb1-32d66e5bea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| sal|\n",
      "+----+\n",
      "| 800|\n",
      "|1600|\n",
      "|1250|\n",
      "|2975|\n",
      "|1250|\n",
      "|2850|\n",
      "|2450|\n",
      "|3000|\n",
      "|5000|\n",
      "|1500|\n",
      "|1100|\n",
      "| 950|\n",
      "|3000|\n",
      "|1300|\n",
      "|3200|\n",
      "+----+\n",
      "\n",
      "+--------+--------+----------+---------+------------------+------------------+\n",
      "|max(sal)|min(sal)|first(sal)|last(sal)|          avg(sal)|round(avg(sal), 0)|\n",
      "+--------+--------+----------+---------+------------------+------------------+\n",
      "|    5000|     800|       800|     3200|2148.3333333333335|            2148.0|\n",
      "+--------+--------+----------+---------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select('sal').show()\n",
    "emp_df.select(max('sal'), min('sal'), first('sal'), last('sal'), avg('sal'), round(avg('sal'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e405fc62-c1a9-43fa-b2a8-df01d256186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.select('sal').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4348492e-6dbe-4b87-99dd-be0a2e14dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.selectExpr('sum(distinct(sal))').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7b45af9-b430-44b6-99c2-6fdc016f8fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------------+\n",
      "|total_transaction|avg_salary|       mean_salary|\n",
      "+-----------------+----------+------------------+\n",
      "|            32225|   2148.33|2148.3333333333335|\n",
      "+-----------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total_salary / total_transaction, avg_salary, mean_salary\n",
    "emp_df.selectExpr('sum(sal) as total_transaction', 'round(avg(sal), 2) as avg_salary', 'mean(sal) as mean_salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb2522-f661-489b-a93c-717e6d76c75c",
   "metadata": {},
   "source": [
    "select job, count, sum   \n",
    "group by job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8fb101a3-a822-4b90-b1de-b1ce2a6755c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+--------+\n",
      "|      job|qty|count(job)|sum(sal)|\n",
      "+---------+---+----------+--------+\n",
      "|  ANALYST|  2|         2|    6000|\n",
      "| SALESMAN|  4|         4|    5600|\n",
      "|    CLERK|  5|         5|    7350|\n",
      "|  MANAGER|  3|         3|    8275|\n",
      "|PRESIDENT|  1|         1|    5000|\n",
      "+---------+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy('job').agg(\n",
    "    count('job').alias('qty'),\n",
    "    expr('count(job)'),\n",
    "    sum('sal')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0a041dc-f9d8-4484-a081-46432082d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+\n",
      "|      job|SAL_AVG|SAL_STDEV|\n",
      "+---------+-------+---------+\n",
      "|  ANALYST| 3000.0|      0.0|\n",
      "| SALESMAN| 1400.0|   177.95|\n",
      "|    CLERK| 1470.0|   984.63|\n",
      "|  MANAGER|2758.33|   274.24|\n",
      "|PRESIDENT| 5000.0|     NULL|\n",
      "+---------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sal 의 평균 SAL_AVG 표준편차 SAL_STDEV 를 job 별로 출력 round 2\n",
    "\n",
    "emp_df.groupBy('job').agg(\n",
    "    round(avg('sal'), 2).alias('SAL_AVG'),\n",
    "    expr('round(std(sal), 2) as SAL_STDEV')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "73fc6793-31fa-4110-b498-303d81d65102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 급여 탑10\n",
    "emp_df.select('*').sort(emp_df.sal.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1d9ac68b-1340-42c4-ae4a-2614d3192f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "seeAllRanl = rank().over(Window.orderBy(desc('sal')))\n",
    "rank_df = emp_df.withColumn('salary_rank', seeAllRanl)\n",
    "rank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "46d6302d-54d1-430a-b180-999227f9d427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (PARTITION BY job ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직무별 rank\n",
    "# Window.partitionBy()\n",
    "# job_rank_df 작성\n",
    "windowspec1 = Window.partitionBy('job').orderBy(desc('sal'))\n",
    "salJobRank = rank().over(windowspec1)\n",
    "salJobRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7799576d-89c3-4514-b11f-8c54820dd0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+----+----------+----+----+------+---------------+\n",
      "|empno|ename|    job| mgr|  hiredate| sal|comm|deptno|salary_job_rank|\n",
      "+-----+-----+-------+----+----------+----+----+------+---------------+\n",
      "| 7788|SCOTT|ANALYST|7566|1987-04-19|3000|NULL|    20|              1|\n",
      "| 7902| FORD|ANALYST|7566|1981-12-03|3000|NULL|    20|              1|\n",
      "| 9292| JACK|  CLERK|7782|1982-01-23|3200|NULL|    70|              1|\n",
      "+-----+-----+-------+----+----------+----+----+------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn('salary_job_rank', salJobRank).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a8ca1df9-a3cf-4a34-9465-da89f4ddcf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               2|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               5|\n",
      "| JAMES|    30| 950|               6|\n",
      "|  JACK|    70|3200|               1|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 순위\n",
    "from pyspark.sql.functions import rank, dense_rank, row_number, col, desc\n",
    "\n",
    "# 2. 부서별 급여 순위\n",
    "dept_window_spec = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "df_with_dept_rank = emp_df.withColumn('dept_salary_rank', \n",
    "                                  row_number().over(dept_window_spec))\n",
    "df_with_dept_rank.select('ename', 'deptno', 'sal', 'dept_salary_rank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9cae56d0-04f4-4401-b1fd-b3f4f8be7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------------+\n",
      "| ename|deptno| sal|cumulative_salary|\n",
      "+------+------+----+-----------------+\n",
      "| CLARK|    10|2450|             2450|\n",
      "|  KING|    10|5000|             7450|\n",
      "|MILLER|    10|1300|             8750|\n",
      "| SMITH|    20| 800|              800|\n",
      "| JONES|    20|2975|             3775|\n",
      "| SCOTT|    20|3000|             6775|\n",
      "| ADAMS|    20|1100|             7875|\n",
      "|  FORD|    20|3000|            10875|\n",
      "| ALLEN|    30|1600|             1600|\n",
      "|  WARD|    30|1250|             2850|\n",
      "|MARTIN|    30|1250|             4100|\n",
      "| BLAKE|    30|2850|             6950|\n",
      "|TURNER|    30|1500|             8450|\n",
      "| JAMES|    30| 950|             9400|\n",
      "|  JACK|    70|3200|             3200|\n",
      "+------+------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 누적급여 sum sal over\n",
    "window_spec_sum = Window.partitionBy('deptno').orderBy('empno')\n",
    "df_cumulative = emp_df.withColumn('cumulative_salary', \n",
    "                                sum('sal').over(window_spec_sum))\n",
    "df_cumulative.select('ename', 'deptno', 'sal', 'cumulative_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "da3d4897-ae30-4474-9692-9ff59683ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|deptno|  sal|\n",
      "+------+-----+\n",
      "|    20|10875|\n",
      "|    10| 8750|\n",
      "|    70| 3200|\n",
      "|    30| 9400|\n",
      "+------+-----+\n",
      "\n",
      "+------+------+----+-----------------+\n",
      "| ename|deptno| sal|cumulative_salary|\n",
      "+------+------+----+-----------------+\n",
      "| CLARK|    10|2450|             2450|\n",
      "|  KING|    10|5000|             7450|\n",
      "|MILLER|    10|1300|             8750|\n",
      "| SMITH|    20| 800|              800|\n",
      "| JONES|    20|2975|             3775|\n",
      "| SCOTT|    20|3000|             6775|\n",
      "| ADAMS|    20|1100|             7875|\n",
      "|  FORD|    20|3000|            10875|\n",
      "| ALLEN|    30|1600|             1600|\n",
      "|  WARD|    30|1250|             2850|\n",
      "|MARTIN|    30|1250|             4100|\n",
      "| BLAKE|    30|2850|             6950|\n",
      "|TURNER|    30|1500|             8450|\n",
      "| JAMES|    30| 950|             9400|\n",
      "|  JACK|    70|3200|             3200|\n",
      "+------+------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 누적 급여\n",
    "emp_df.groupBy('deptno').agg(\n",
    "    sum('sal').alias(\"sal\")\n",
    ").show()\n",
    "\n",
    "\n",
    "window_spec_sum = Window.partitionBy('deptno').orderBy('empno')\n",
    "df_cumulative = emp_df.withColumn('cumulative_salary', \n",
    "                                sum('sal').over(window_spec_sum))\n",
    "df_cumulative.select('ename', 'deptno', 'sal', 'cumulative_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ba133fff-8087-4a93-ab3e-b38957b0ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+------------------+\n",
      "| ename|deptno| sal|   dept_avg_salary|\n",
      "+------+------+----+------------------+\n",
      "| CLARK|    10|2450|2916.6666666666665|\n",
      "|  KING|    10|5000|2916.6666666666665|\n",
      "|MILLER|    10|1300|2916.6666666666665|\n",
      "| SMITH|    20| 800|            2175.0|\n",
      "| JONES|    20|2975|            2175.0|\n",
      "| SCOTT|    20|3000|            2175.0|\n",
      "| ADAMS|    20|1100|            2175.0|\n",
      "|  FORD|    20|3000|            2175.0|\n",
      "| ALLEN|    30|1600|1566.6666666666667|\n",
      "|  WARD|    30|1250|1566.6666666666667|\n",
      "|MARTIN|    30|1250|1566.6666666666667|\n",
      "| BLAKE|    30|2850|1566.6666666666667|\n",
      "|TURNER|    30|1500|1566.6666666666667|\n",
      "| JAMES|    30| 950|1566.6666666666667|\n",
      "|  JACK|    70|3200|            3200.0|\n",
      "+------+------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 평균 급여와 직원 개별 급여 비교?\n",
    "window_spec_avg = Window.partitionBy('deptno')\n",
    "df_avg_compare = emp_df.withColumn('dept_avg_salary', \n",
    "                        avg('sal').over(window_spec_avg))\n",
    "df_avg_compare.select('ename', 'deptno', 'sal', 'dept_avg_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "401af5b7-e9f0-47b9-92e1-6c5202232d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  NULL|     NULL|      15|   32225|\n",
      "|  NULL|  ANALYST|       2|    6000|\n",
      "|  NULL|    CLERK|       5|    7350|\n",
      "|  NULL|  MANAGER|       3|    8275|\n",
      "|  NULL|PRESIDENT|       1|    5000|\n",
      "|  NULL| SALESMAN|       4|    5600|\n",
      "|    10|     NULL|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     NULL|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     NULL|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     NULL|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.cube('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "307657bc-d8e4-4979-bdb9-11069602038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+--------+------------------+\n",
      "|deptno|count(1)|min(sal)|max(sal)|round(avg(sal), 2)|\n",
      "+------+--------+--------+--------+------------------+\n",
      "|  NULL|      15|     800|    5000|           2148.33|\n",
      "|    10|       3|    1300|    5000|           2916.67|\n",
      "|    20|       5|     800|    3000|            2175.0|\n",
      "|    30|       6|     950|    2850|           1566.67|\n",
      "|    70|       1|    3200|    3200|            3200.0|\n",
      "+------+--------+--------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최소, 최대, 평균\n",
    "emp_df.cube('deptno').agg(count('*'), min('sal'), max('sal'), round(avg('sal'), 2)).orderBy('deptno').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "83bd211d-69b8-4d6a-a31e-d839dbb12bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+--------+------------------+\n",
      "|      job|count(1)|min(sal)|max(sal)|round(avg(sal), 2)|\n",
      "+---------+--------+--------+--------+------------------+\n",
      "|     NULL|      15|     800|    5000|           2148.33|\n",
      "|  ANALYST|       2|    3000|    3000|            3000.0|\n",
      "|    CLERK|       5|     800|    3200|            1470.0|\n",
      "|  MANAGER|       3|    2450|    2975|           2758.33|\n",
      "|PRESIDENT|       1|    5000|    5000|            5000.0|\n",
      "| SALESMAN|       4|    1250|    1600|            1400.0|\n",
      "+---------+--------+--------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최소, 최대, 평균\n",
    "emp_df.cube('job').agg(count('*'), min('sal'), max('sal'), round(avg('sal'), 2)).orderBy('job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "564748fc-89ff-46af-83d3-e4be68613372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+---------+----+----------+----+----+----------+--------+\n",
      "|deptno|empno| ename|      job| mgr|  hiredate| sal|comm|     dname|     loc|\n",
      "+------+-----+------+---------+----+----------+----+----+----------+--------+\n",
      "|    20| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|  RESEARCH|  DALLAS|\n",
      "|    30| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|     SALES| CHICAGO|\n",
      "|    30| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|     SALES| CHICAGO|\n",
      "|    20| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|  RESEARCH|  DALLAS|\n",
      "|    30| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|     SALES| CHICAGO|\n",
      "|    30| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|     SALES| CHICAGO|\n",
      "|    10| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|ACCOUNTING|NEW YORK|\n",
      "|    20| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|  RESEARCH|  DALLAS|\n",
      "|    10| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|ACCOUNTING|NEW YORK|\n",
      "|    30| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|     SALES| CHICAGO|\n",
      "|    20| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|  RESEARCH|  DALLAS|\n",
      "|    30| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|     SALES| CHICAGO|\n",
      "|    20| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|  RESEARCH|  DALLAS|\n",
      "|    10| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|ACCOUNTING|NEW YORK|\n",
      "+------+-----+------+---------+----+----------+----+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_df = emp_df.join(dept_df, on='deptno', how='inner')\n",
    "join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "65053128-d0d6-4ca3-99d1-dfd503fac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8e370-db50-4c76-ad9f-f4e11d5e5aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
