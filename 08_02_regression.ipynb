{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a5759b-d7cb-4f47-98c3-c0605b54090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef39ca4-cdaa-44ab-a393-dd7bb8a5d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"taxi-fare-prediciton_2nd\")\\\n",
    "                            .config(\"spark.driver.memory\", '8g')\\\n",
    "                            .config(\"spark.excutor.memory\", '8g')\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4afdc4a-ae8c-40ba-b796-1039f3f42afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "trip_data_path = os.path.join(cwd, '../learning_spark_data', 'trips', '*.csv')\n",
    "file_path = f\"file:///{trip_data_path.replace(os.sep,'/') }\"\n",
    "trip_df = spark.read.csv(file_path, inferSchema=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622097b2-d8f7-44a5-89fb-60ad54cbf80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6195a783-11b1-4800-a8dc-79e06b6c7403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2021-03-01 00:22:02|  2021-03-01 00:23:22|              1|          0.0|         1|                 N|         264|         264|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       2| 2021-03-01 00:24:48|  2021-03-01 00:24:56|              1|          0.0|         1|                 N|         152|         152|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|\n",
      "|       2| 2021-03-01 00:25:17|  2021-03-01 00:31:01|              1|          0.0|         1|                 N|         152|         152|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|\n",
      "|       1| 2021-03-01 00:07:40|  2021-03-01 00:31:23|              0|         16.5|         4|                 N|         138|         265|           1|       51.0|  0.5|    0.5|     11.65|        6.12|                  0.3|       70.07|                 0.0|\n",
      "|       2| 2021-03-01 00:02:13|  2021-03-01 00:06:01|              1|         1.13|         1|                 N|          68|         264|           1|        5.5|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d25664-4868-4133-b5e5-99e742f1a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    trip_distance,\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    total_amount\n",
    "FROM\n",
    "    trips\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND TO_DATE(tpep_pickup_datetime) >= '2021-01-01'\n",
    "    AND TO_DATE(tpep_pickup_datetime) < '2021-08-01'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9820c137-c27f-45cf-8d6a-933e85dfd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aff25ae-d07e-421b-b740-6e57b7db18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(machine, data, param, translate=None, Tparam=None):\n",
    "    train_data, test_data = data.randomSplit([0.7,0.3], seed=12)\n",
    "\n",
    "    if translate is not None:\n",
    "        translated = translate(**Vparam)\n",
    "        train_data = translated.transform(train_data)\n",
    "        test_data = translated.transform(test_data)\n",
    "    \n",
    "    learning = machine(**param)\n",
    "    model = learning.fit(train_data)\n",
    "    \n",
    "    predic = model.transform(test_data)\n",
    "    \n",
    "    print(f'rootMeanSquaredError: {model.summary.rootMeanSquaredError}')\n",
    "    print(f\"r2: {model.summary.r2}\")\n",
    "    predic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715ec6a-c5aa-4760-b750-f0b68b61dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c1ef18-6b8c-4c84-acdd-ae1c7249dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8,0.2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86b5f5af-e672-4f5f-b7b3-da213bb7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b082193-02f1-42e8-833f-4ee2b05137e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_f9ba487d6676,\n",
       " OneHotEncoder_99d0c03cfd4b,\n",
       " StringIndexer_110297b55d65,\n",
       " OneHotEncoder_45282655e031,\n",
       " StringIndexer_41651a78f423,\n",
       " OneHotEncoder_46632d853287]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "cat_features = ['pickup_location_id', 'dropoff_location_id', 'day_of_week']\n",
    "for cat in cat_features:\n",
    "    cat_index = StringIndexer(inputCol=cat, outputCol=cat+'_idx').setHandleInvalid('keep')\n",
    "    onehot_encode = OneHotEncoder(inputCols= [cat_index.getOutputCol()], #_idx col\n",
    "                                  outputCols=[cat+'_onehot'] #postfix\n",
    "                                 )\n",
    "    stages += [cat_index, onehot_encode ] #collist\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b55e7caa-3198-45ef-b674-df3df5e9f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_f9ba487d6676,\n",
       " OneHotEncoder_99d0c03cfd4b,\n",
       " StringIndexer_110297b55d65,\n",
       " OneHotEncoder_45282655e031,\n",
       " StringIndexer_41651a78f423,\n",
       " OneHotEncoder_46632d853287,\n",
       " VectorAssembler_9ea5b1c33373,\n",
       " StandardScaler_da60ca07bfcf,\n",
       " VectorAssembler_1597c1226205,\n",
       " StandardScaler_23d4f0edc045,\n",
       " VectorAssembler_5cd4fe6c20bd,\n",
       " StandardScaler_9228aaa8aa72]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "num_features = [ 'passenger_count', 'trip_distance', 'pickup_time']\n",
    "\n",
    "for num in num_features:\n",
    "    num_assembler = VectorAssembler(inputCols=[num], outputCol=num+'_vector')\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=num+'_scaled')\n",
    "    stages += [num_assembler, num_scaler]\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496430c5-9d8f-41b2-a7d5-ab595a640471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_location_id_onehot',\n",
       " 'dropoff_location_id_onehot',\n",
       " 'day_of_week_onehot',\n",
       " 'passenger_count_scaled',\n",
       " 'trip_distance_scaled',\n",
       " 'pickup_time_scaled']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler_input = [cat+'_onehot' for cat in cat_features] + [num+'_scaled' for num in num_features]\n",
    "assembler_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e613958-fe18-4a5f-9bea-44ae9a9f658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_f9ba487d6676,\n",
       " OneHotEncoder_99d0c03cfd4b,\n",
       " StringIndexer_110297b55d65,\n",
       " OneHotEncoder_45282655e031,\n",
       " StringIndexer_41651a78f423,\n",
       " OneHotEncoder_46632d853287,\n",
       " VectorAssembler_9ea5b1c33373,\n",
       " StandardScaler_da60ca07bfcf,\n",
       " VectorAssembler_1597c1226205,\n",
       " StandardScaler_23d4f0edc045,\n",
       " VectorAssembler_5cd4fe6c20bd,\n",
       " StandardScaler_9228aaa8aa72,\n",
       " VectorAssembler_818a77af4b7b]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=assembler_input, outputCol='feature_vector')\n",
    "stages += [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6819d1bc-a58b-4d2e-910a-7e5f132bdd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- pickup_location_id: integer (nullable = true)\n",
      " |-- dropoff_location_id: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- pickup_location_id_idx: double (nullable = false)\n",
      " |-- pickup_location_id_onehot: vector (nullable = true)\n",
      " |-- dropoff_location_id_idx: double (nullable = false)\n",
      " |-- dropoff_location_id_onehot: vector (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = false)\n",
      " |-- day_of_week_onehot: vector (nullable = true)\n",
      " |-- passenger_count_vector: vector (nullable = true)\n",
      " |-- passenger_count_scaled: vector (nullable = true)\n",
      " |-- trip_distance_vector: vector (nullable = true)\n",
      " |-- trip_distance_scaled: vector (nullable = true)\n",
      " |-- pickup_time_vector: vector (nullable = true)\n",
      " |-- pickup_time_scaled: vector (nullable = true)\n",
      " |-- feature_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "fitted_transform = pipeline.fit(train_df)\n",
    "vtrain_df = fitted_transform.transform(train_df)\n",
    "vtrain_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28b18d8f-1c53-4f76-8bb8-f7181b691349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      feature_vector|\n",
      "+--------------------+\n",
      "|(533,[62,311,527,...|\n",
      "|(533,[62,280,526,...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vtrain_df.select('feature_vector').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf37fd1f-3fc4-4b67-a296-b1b699a1e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=50, solver='normal', \n",
    "                 labelCol='total_amount', featuresCol='feature_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a24a8420-cd61-4686-bed5-a8af4ec36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(vtrain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d48f0a42-ebbd-430b-b619-780e8c1ac3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트데이터도 변환\n",
    "vtest_df = fitted_transform.transform(test_df)\n",
    "#테스트데이터로 예측\n",
    "pred = model.transform(vtest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7662d-6681-4c59-ac9b-b0b56ae1365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.select('total_amount', 'prediction').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95a00c-243f-4a0a-b9c7-915078a2f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary.r2, model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca985f-746d-4c94-85b8-02fa9c15e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34131fed-b54c-4a6d-a43d-2a66adb5c12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
