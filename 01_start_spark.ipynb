{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7f1aa2-12d2-40d9-872d-617736148926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59134d8e-6fd3-4476-89ff-7bfce7f51937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3555f8-e702-42e1-8a26-a923b8897463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81851b7f-c366-40fd-9772-43ff66186c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.8.1\" 2023-08-24\n",
      "OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857c13e0-f7bb-4949-b614-6ecc19b171ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark/python\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed927fb-3efc-4d81-90d9-797a2e61b9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPARK_HOME\n",
    "import os\n",
    "os.environ.get('SPARK_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6061b22-7020-4910-a333-daf024930f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JAVA_HOME\n",
    "os.environ.get('JAVA_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c3d6ea-ff0d-459f-b49c-659d2f7002fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip:/usr/local/spark/python:'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PYTHONPATH\n",
    "os.environ.get('PYTHONPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0118a815-28ef-4c54-88e8-f33966e6071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining\n",
    "#SparkContext.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8f4b7d-91cc-41ad-a5b4-c4b594aad910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d25af1435a92:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f201dd4e010>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f99009-fc50-4dd3-a762-e582634566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8815d40-ae81-469d-8d48-6b1688941802",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0b06d6f-7443-4448-883f-417277255e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d25af1435a92:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f201dd6ac10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4a7406-9885-4f93-ba9d-c4ac21882a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Alice',1), ('Bob', 2), ('Charlie',3) ]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287b889-23d9-4be0-b96e-9c95562af178",
   "metadata": {},
   "source": [
    "### DataFrame 객체(분산객체)를 생성 <> 판다스의 데이터프레임이 아님."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f8e9fc-65c0-4be0-ab71-a6dcb3840aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Value[1]'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = spark.createDataFrame( data, ['Name','Value'])\n",
    "data1[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cf1a637-ac9b-402c-98ed-1d1f32c95a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6159fa39-2206-470c-b690-8150cb4185f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Bob|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Name == 'Bob').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0298d900-bb74-40fe-9757-d5599627835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Value > 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "899efba0-bb76-40cb-a21b-c5c201ab3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec4ed38b-a7b7-4196-9990-c91430665c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4e1f5ef-f52b-411b-b365-c5325c3838ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Bob|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( 'select * from people where Name=\"Bob\"' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200e7721-f3c1-4ba3-95ae-49ca5da0f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( 'select * from people where Value>2' ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ae342-d0c8-47b2-8c1e-77b50bf445f5",
   "metadata": {},
   "source": [
    "# RDD 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "173d8695-2ea6-4c39-afb6-f7bcfc3ad073",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09464ccb-742d-4d2c-af3a-b589cfd42b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[26] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5]) #직접 생성\n",
    "rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf91f1-5091-4ca0-85ec-b8f21964b666",
   "metadata": {},
   "source": [
    "### rdd 객체를 출력하는 함수 - n개를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26222adb-b452-45a4-b84b-6d718e307d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfdcc9-b694-4ab5-a4f6-728b42402d76",
   "metadata": {},
   "source": [
    "### map 연산 : rdd 값으로 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad1ace25-3e66-41ce-afd4-e4075b6281f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[32] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd = rdd.map(lambda x:x*x)\n",
    "squared_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c5ba74b-2552-4ba3-849c-6c831bf36378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "906c5f7f-b951-4943-96e4-d07b8b10f06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4713b031-a6fa-4df4-8742-0265f3d17e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace106c-c5cb-49e3-83a7-9caa446dcb0c",
   "metadata": {},
   "source": [
    "#  ML lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "749d00f9-33b8-4a86-b633-5a29c02cbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bc55b68-4c68-47a6-81b6-209609f7e9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_age = [('Alice',25), ('Bob', 30), ('Charlie',33) ]\n",
    "data2 = spark.createDataFrame( data_age, ['Name','Age'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46b25f54-4d9f-4ef4-802d-3410fdf80bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 33|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dbdd302-4d43-4d14-9d04-1cadf8d6ca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint, features: vector]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = ['Age'], outputCol='features')\n",
    "vector_df = assembler.transform(data2)\n",
    "vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1057b91b-e844-43de-802c-afe6edd02b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   Name|Age|features|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|  [25.0]|\n",
      "|    Bob| 30|  [30.0]|\n",
      "|Charlie| 33|  [33.0]|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0f1ae4a-babd-4893-bab7-73c58e05e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='Age')\n",
    "model = lr.fit(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "164a34ab-0665-4d3c-b2cd-1e5713663818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint, features: vector, prediction: double]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.transform(vector_df)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3087831-f4bc-4529-b85d-5286eb2d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+-----------------+\n",
      "|   Name|Age|features|       prediction|\n",
      "+-------+---+--------+-----------------+\n",
      "|  Alice| 25|  [25.0]|24.99999999999993|\n",
      "|    Bob| 30|  [30.0]|30.00000000000001|\n",
      "|Charlie| 33|  [33.0]|33.00000000000006|\n",
      "+-------+---+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17e8074e-58c4-4865-af0a-72e3ed1d5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5282ee-9867-46f4-81a7-7094e7a7318a",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b59898c2-4144-455a-8c10-fa6dce57facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6691cf63-2112-4d7a-907e-15b6a843d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dd06878-3534-4e2d-8938-2f25c081a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.format('socket')\\\n",
    "            .option('host', 'localhost')\\\n",
    "            .option('port',9999)\\\n",
    "            .load()  #STREAMMING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b0d288e-8226-499b-9e5c-93d92cfd62ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2701730103.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[70], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    words = lines.select(explode(split(lines.value, ' ' )).alias('word')\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "words = lines.select(explode(split(lines.value, ' ' )).alias('word')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "111b7eb7-da43-4170-80fd-0e95fa5ffc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
